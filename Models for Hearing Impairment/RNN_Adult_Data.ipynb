{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOG06lN3lziR2D9Oo2zIe87"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pLOiAFnCVA5","executionInfo":{"status":"ok","timestamp":1697649803344,"user_tz":480,"elapsed":2050,"user":{"displayName":"L D","userId":"04532464313143537675"}},"outputId":"0b78896a-17eb-458f-d1f4-2c074815774a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Mount drive to access stored data\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqc0aq6LCWZU"},"outputs":[],"source":["# Set the data path to where the datasets are stored\n","dataset_path = '/content/drive/My Drive/Difficult Words Data/DHH Adult Data/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucedf2L99nk_"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HRBjXKaY9o04"},"outputs":[],"source":["# Load data from the Excel file\n","data = pd.read_excel(dataset_path + 'complete_adult_data2.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMXOhg0U-AiH","executionInfo":{"status":"ok","timestamp":1697649808765,"user_tz":480,"elapsed":5,"user":{"displayName":"L D","userId":"04532464313143537675"}},"outputId":"0ab53188-f8e2-4836-8648-3569023380a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["            word  length  syllables  senses  synonyms  hyponyms  hypernyms  \\\n","1074       awake       5          2       3         8         0          1   \n","2689     college       7          2       3         0         3          3   \n","2729      comedy       6          3       2         3        10          2   \n","7716       laura       5          2       0         0         0          0   \n","1579     boiling       7          2       8         7         9          8   \n","10203       plot       4          1       8         7        11          8   \n","14886       whip       4          1      11        16        17         11   \n","955    attempted       9          3       3         7         8          2   \n","1575        body       4          2      12        10        52         10   \n","5060   extracted       9          3       8        14         5          8   \n","\n","       subtitles  simple  subtlex  average  overall_label  \n","1074       -14.2   -17.1    -14.0   1.8182              0  \n","2689       -12.5   -11.5    -12.3   1.4545              0  \n","2729       -14.8   -12.8    -15.1   1.6667              0  \n","7716       -14.1   -15.4    -13.9   2.5455              1  \n","1579       -16.5   -15.5    -16.6   1.7273              0  \n","10203      -15.3   -14.3    -15.2   1.7273              0  \n","14886      -15.0   -17.0    -15.0   1.7273              0  \n","955        -16.3   -14.8    -15.8   2.4545              0  \n","1575       -11.4   -10.7    -11.1   1.2727              0  \n","5060       -18.7   -16.9    -18.6   2.4000              0  \n"]}],"source":["# Create and view a sample of the data, make sure it loaded correctly\n","sampled_data = data.sample(n=10)\n","print(sampled_data)"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Split data into input (X) and output (y)\n","X = data['word'].astype(str)\n","y = data['average'].astype(float)\n","\n","# Tokenization\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X)\n","X_seq = tokenizer.texts_to_sequences(X)\n","\n","# Padding sequences\n","max_seq_length = 20  # Adjust as needed\n","X_padded = pad_sequences(X_seq, maxlen=max_seq_length, padding='post', truncating='post')\n","\n","# Split data into training and validation/test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)"],"metadata":{"id":"_NKCNQgAxmHv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","\n","# Define the model\n","model = Sequential()\n","\n","# Add an Embedding layer for word embeddings\n","vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size + 1 for out-of-vocabulary words\n","embedding_dim = 50  # Adjust as needed\n","model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length))\n","\n","# Add a SimpleRNN layer\n","rnn_units = 32  # Adjust as needed\n","model.add(SimpleRNN(units=rnn_units, activation='relu'))\n","\n","# Add an output layer\n","model.add(Dense(units=1, activation='linear'))  # Linear activation for regression\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Summary of the model architecture\n","model.summary()\n","\n","# Train the model\n","batch_size = 64\n","epochs = 10\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBxtRyJwzIgL","executionInfo":{"status":"ok","timestamp":1697649851624,"user_tz":480,"elapsed":42210,"user":{"displayName":"L D","userId":"04532464313143537675"}},"outputId":"99c526a2-f9cd-4cee-8634-1ba19260dda0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 20, 50)            759050    \n","                                                                 \n"," simple_rnn_2 (SimpleRNN)    (None, 32)                2656      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 761739 (2.91 MB)\n","Trainable params: 761739 (2.91 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","152/152 [==============================] - 4s 19ms/step - loss: 0.9805 - val_loss: 0.4124\n","Epoch 2/10\n","152/152 [==============================] - 3s 19ms/step - loss: 0.3660 - val_loss: 0.4874\n","Epoch 3/10\n","152/152 [==============================] - 4s 25ms/step - loss: 0.1476 - val_loss: 0.4551\n","Epoch 4/10\n","152/152 [==============================] - 3s 22ms/step - loss: 0.0715 - val_loss: 0.4206\n","Epoch 5/10\n","152/152 [==============================] - 3s 18ms/step - loss: 0.0376 - val_loss: 0.4197\n","Epoch 6/10\n","152/152 [==============================] - 3s 17ms/step - loss: 0.0190 - val_loss: 0.4192\n","Epoch 7/10\n","152/152 [==============================] - 3s 19ms/step - loss: 0.0096 - val_loss: 0.4243\n","Epoch 8/10\n","152/152 [==============================] - 4s 25ms/step - loss: 0.0056 - val_loss: 0.4207\n","Epoch 9/10\n","152/152 [==============================] - 3s 18ms/step - loss: 0.0044 - val_loss: 0.4200\n","Epoch 10/10\n","152/152 [==============================] - 3s 18ms/step - loss: 0.0032 - val_loss: 0.4220\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x789acf481240>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","\n","y_pred = model.predict(X_test)\n","mae = mean_absolute_error(y_test, y_pred)\n","print(mae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJjbxNcizpuI","executionInfo":{"status":"ok","timestamp":1697649852540,"user_tz":480,"elapsed":921,"user":{"displayName":"L D","userId":"04532464313143537675"}},"outputId":"ade17068-49a1-45b6-9fca-e2a0ca41560f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["95/95 [==============================] - 0s 2ms/step\n","0.5085964440291735\n"]}]}]}